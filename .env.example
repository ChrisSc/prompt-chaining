# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_TITLE=Prompt Chaining Workflow
API_VERSION=0.4.1

# Environment
ENVIRONMENT=development

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Claude API Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Service Model Display Name
SERVICE_MODEL_NAME=prompt-chaining

# Prompt-Chaining Configuration (LangGraph StateGraph Orchestration)
# The three-step prompt-chaining pattern: analyze → process → synthesize
# Each step has independent model, token limits, temperature, and timeout configuration

# Analyze Step Configuration
# First step: Parse user intent, extract key entities, assess complexity
CHAIN_ANALYZE_MODEL=claude-haiku-4-5-20251001
CHAIN_ANALYZE_MAX_TOKENS=2048
CHAIN_ANALYZE_TEMPERATURE=0.5
CHAIN_ANALYZE_TIMEOUT=15

# Process Step Configuration
# Second step: Generate content based on analysis results
CHAIN_PROCESS_MODEL=claude-haiku-4-5-20251001
CHAIN_PROCESS_MAX_TOKENS=2048
CHAIN_PROCESS_TEMPERATURE=0.7
CHAIN_PROCESS_TIMEOUT=30

# Synthesize Step Configuration
# Third step: Polish and format the final response (streaming)
CHAIN_SYNTHESIZE_MODEL=claude-haiku-4-5-20251001
CHAIN_SYNTHESIZE_MAX_TOKENS=2048
CHAIN_SYNTHESIZE_TEMPERATURE=0.5
CHAIN_SYNTHESIZE_TIMEOUT=20

# Prompt-Chaining Validation Gates
# Enable validation gates between steps to enforce quality thresholds
CHAIN_ENABLE_VALIDATION=true
# Strict validation: fail fast on invalid outputs (true) vs warn and continue (false)
CHAIN_STRICT_VALIDATION=false

# CORS Configuration
CORS_ORIGINS=["*"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["*"]
CORS_ALLOW_HEADERS=["*"]

# Streaming Configuration
STREAMING_TIMEOUT=60
STREAMING_CHUNK_BUFFER=0

# Request Timeout Configuration (Phase-specific enforcement)
# These settings control maximum duration for each phase of request processing
# Total budget: worker_coordination_timeout + synthesis_timeout
# Prevents runaway requests from consuming resources indefinitely and controls LLM costs

# Worker Coordination Timeout (seconds)
# Maximum time for parallel worker execution phase
# Workers execute their tasks in parallel using asyncio.gather()
# Timeout prevents indefinite execution of worker tasks
# Default: 45 seconds
# Valid range: 1-270 seconds
# Increase for: Complex tasks with many workers or slow models
# Decrease for: Stricter latency requirements
WORKER_COORDINATION_TIMEOUT=45

# Synthesis Timeout (seconds)
# Maximum time for final synthesis and streaming phase
# Synthesizer aggregates results and streams final response
# Timeout prevents slow synthesis responses from blocking clients
# Default: 30 seconds
# Valid range: 1-270 seconds
# Increase for: Large response generation tasks
# Decrease for: Strict response latency requirements
SYNTHESIS_TIMEOUT=30

# Request Validation
# Maximum request body size in bytes (default: 1048576 = 1MB)
# Protects against memory exhaustion attacks by limiting request payload size
# Applied to POST, PUT, PATCH requests; GET and /health/* endpoints are exempt
# Valid range: 1024 (1KB) to 10485760 (10MB)
MAX_REQUEST_BODY_SIZE=1048576

# Optional: Loki logging endpoint
# LOKI_URL=http://localhost:3100

# LangChain & LangGraph Integration
# LangChain 1.0.0+ and LangGraph 1.0.0+ are now available as dependencies
# These are used for building prompt chains and composing multi-step agentic workflows
# No additional configuration required - they are included in pip install -e ".[dev]"

# JWT Bearer Token Authentication Configuration
# REQUIRED for all protected API endpoints (/v1/chat/completions, /v1/models)
# IMPORTANT: Must be a strong, randomly-generated secret with at least 32 characters
# Do NOT use weak secrets like "test" or "password"
# Generate a secure secret with this command:
#   python -c "import secrets; print(secrets.token_urlsafe(32))"
# Then copy and paste the output below
JWT_SECRET_KEY=your_jwt_secret_key_here_minimum_32_characters_required_for_security

# JWT Signing Algorithm (do not change unless you understand the implications)
# Default: HS256 (HMAC with SHA-256, symmetric algorithm)
# Alternatives: HS512, HS384 (HMAC variants), RS256, RS512 (RSA, requires key pairs)
JWT_ALGORITHM=HS256

# Security Headers Configuration
# Enable security headers middleware (default: true)
# Headers added: X-Content-Type-Options, X-Frame-Options, X-XSS-Protection, Strict-Transport-Security (HTTPS only)
ENABLE_SECURITY_HEADERS=true

# Rate Limiting Configuration
# Enable API rate limiting (default: true)
# Protects against abuse and controls API usage
RATE_LIMIT_ENABLED=true

# Default rate limit applied to all endpoints without specific limits
# Format: <count>/<time_unit> where time_unit is second, minute, hour, or day
RATE_LIMIT_DEFAULT=100/hour

# Chat completions endpoint rate limit (most resource-intensive)
RATE_LIMIT_CHAT_COMPLETIONS=10/minute

# Models listing endpoint rate limit (lightweight operation)
RATE_LIMIT_MODELS=60/minute

# Circuit Breaker Configuration
# Enable/disable circuit breaker pattern for external API calls
# Default: true (recommended for production)
CIRCUIT_BREAKER_ENABLED=true

# Number of consecutive failures before opening circuit
# Default: 3, Valid range: 1-10
# Conservative setting prevents cascading failures
CIRCUIT_BREAKER_FAILURE_THRESHOLD=3

# Seconds to wait before attempting half-open state
# Default: 30, Valid range: 10-300
# Gives failing service time to recover
CIRCUIT_BREAKER_TIMEOUT=30

# Number of successful test attempts needed in half-open state to close circuit
# Default: 1, Valid range: 1-5
CIRCUIT_BREAKER_HALF_OPEN_ATTEMPTS=1

# Retry Configuration
# Maximum number of retry attempts for retryable errors (rate limits, timeouts, server errors)
# Default: 3, Valid range: 1-10
RETRY_MAX_ATTEMPTS=3

# Multiplier for exponential backoff calculation
# Default: 1.0, Valid range: 0.5-5.0
# Higher values = more aggressive backoff
RETRY_EXPONENTIAL_MULTIPLIER=1.0

# Maximum wait time in seconds for exponential backoff
# Default: 30, Valid range: 5-300
# Caps retry delays to prevent excessively long waits
RETRY_EXPONENTIAL_MAX=30
