# Implementation Plan

## Documentation References

This implementation uses curated documentation to break dependency on pre-training:

- **FastAPI Documentation**: `./documentation/fastapi/INDEX_AGENT.md`
- **LangChain Documentation**: `./documentation/langchain/INDEX.md`
- **Pydantic Documentation**: `./documentation/pydantic/LLM_INDEX.md`

Refer to these documents for implementation details, patterns, and examples.

---

- [ ] 1. Add LangChain and LangGraph dependencies
  - Add `langchain`, `langchain-anthropic`, and `langgraph` to `pyproject.toml` dependencies
  - Update dependency versions to latest stable releases
  - Run `pip install -e ".[dev]"` to verify installation
  - _Requirements: 1.1, 1.3_
  - _Documentation: See `./documentation/langchain/INDEX.md` for LangChain installation guide at `oss/python/langchain/install.md`_

- [ ] 2. Create chain state and data models
  - [ ] 2.1 Create `src/orchestrator_worker/models/chains.py` with ChainState TypedDict
    - Define ChainState with messages, analysis, processed_content, final_response, step_metadata fields
    - Use LangGraph's `add_messages` annotation for message accumulation
    - _Requirements: 1.1, 3.4_
    - _Documentation: See `./documentation/langchain/INDEX.md` → LangGraph section → `oss/python/langgraph/overview.md` for StateGraph patterns_
  - [ ] 2.2 Create Pydantic models for step outputs in `models/chains.py`
    - Implement AnalysisOutput model with intent, key_entities, complexity, context fields
    - Implement ProcessOutput model with content, confidence, metadata fields
    - Implement SynthesisOutput model with final_text, formatting fields
    - _Requirements: 2.4, 5.3_
    - _Documentation: See `./documentation/pydantic/LLM_INDEX.md` → CORE section → `models/index.md` for BaseModel fundamentals and `fields/index.md` for Field definition_
  - [ ] 2.3 Create ChainStepConfig and ChainConfig models in `models/chains.py`
    - Define ChainStepConfig with model, max_tokens, temperature, system_prompt_file
    - Define ChainConfig with analyze, process, synthesize step configs and timeout settings
    - _Requirements: 5.2, 5.4_
    - _Documentation: See `./documentation/pydantic/LLM_INDEX.md` → CORE section → `models/index.md` for model composition and nested models_

- [ ] 3. Create system prompts for chain steps
  - [ ] 3.1 Create `src/orchestrator_worker/prompts/chain_analyze.md`
    - Write prompt instructing LLM to analyze user request and extract intent, entities, complexity
    - Include examples of expected JSON output format
    - _Requirements: 2.1, 5.1_
  - [ ] 3.2 Create `src/orchestrator_worker/prompts/chain_process.md`
    - Write prompt instructing LLM to generate response based on analysis
    - Include guidance on using analysis context effectively
    - _Requirements: 2.2, 5.1_
  - [ ] 3.3 Create `src/orchestrator_worker/prompts/chain_synthesize.md`
    - Write prompt instructing LLM to format and polish final response
    - Include formatting guidelines and tone instructions
    - _Requirements: 2.3, 5.1_

- [ ] 4. Implement validation gates
  - [ ] 4.1 Create `src/orchestrator_worker/chains/validation.py` with ValidationGate base class
    - Implement base ValidationGate class with schema validation using Pydantic
    - Add validate() method returning (is_valid, error_message) tuple
    - _Requirements: 2.4, 5.3_
  - [ ] 4.2 Implement AnalysisValidationGate in `chains/validation.py`
    - Validate AnalysisOutput schema
    - Add business logic validation for required fields (intent must be present)
    - _Requirements: 2.4, 5.5_
  - [ ] 4.3 Implement ProcessValidationGate in `chains/validation.py`
    - Validate ProcessOutput schema
    - Add business logic validation for content length and confidence thresholds
    - _Requirements: 2.4, 5.5_
  - [ ] 4.4 Create conditional edge functions for LangGraph
    - Implement should_proceed_to_process() function using AnalysisValidationGate
    - Implement should_proceed_to_synthesize() function using ProcessValidationGate
    - Return "next_step" or "error" based on validation results
    - _Requirements: 2.5, 3.5_

- [ ] 5. Implement chain step functions
  - [ ] 5.1 Create `src/orchestrator_worker/chains/steps.py` with analyze_step function
    - Extract user message from ChainState.messages
    - Initialize ChatAnthropic with Haiku model and load chain_analyze.md prompt
    - Call LLM with system prompt and user message
    - Parse response into AnalysisOutput structure
    - Log step metrics (tokens, cost, duration)
    - Return state update with analysis and messages
    - _Requirements: 2.1, 3.1, 3.3, 4.5_
    - _Documentation: See `./documentation/langchain/INDEX.md` → `oss/python/langchain/models.md` for ChatAnthropic usage and `oss/python/integrations/providers/anthropic.md` for Anthropic integration_
  - [ ] 5.2 Implement process_step function in `chains/steps.py`
    - Extract analysis from ChainState.analysis
    - Build processing prompt from analysis context
    - Initialize ChatAnthropic with Sonnet model and load chain_process.md prompt
    - Call LLM with system prompt and constructed prompt
    - Log step metrics (tokens, cost, duration)
    - Return state update with processed_content and messages
    - _Requirements: 2.2, 3.1, 3.3, 4.5_
    - _Documentation: See `./documentation/langchain/INDEX.md` → `oss/python/langchain/models.md` for model configuration_
  - [ ] 5.3 Implement synthesize_step async generator function in `chains/steps.py`
    - Extract processed_content from ChainState.processed_content
    - Build synthesis prompt from processed content
    - Initialize ChatAnthropic with Haiku model, streaming=True, and load chain_synthesize.md prompt
    - Stream LLM response using astream() method
    - Yield state updates with message chunks and accumulated final_response
    - Log step metrics after streaming completes
    - _Requirements: 2.3, 3.1, 3.3, 4.5_
    - _Documentation: See `./documentation/langchain/INDEX.md` → `oss/python/langchain/streaming.md` for streaming patterns with LangChain_
  - [ ] 5.4 Implement error_step function in `chains/steps.py`
    - Extract error information from ChainState
    - Log error with step name, error message, and full state
    - Return state update with error message in final_response
    - _Requirements: 2.5, 4.2_

- [ ] 6. Build LangGraph state machine
  - [ ] 6.1 Create `src/orchestrator_worker/chains/graph.py` with build_chain_graph function
    - Initialize StateGraph with ChainState
    - Add nodes for analyze, process, synthesize, error steps
    - Add edge from START to analyze
    - Add conditional edge from analyze using should_proceed_to_process
    - Add conditional edge from process using should_proceed_to_synthesize
    - Add edges from synthesize and error to END
    - Compile and return graph
    - _Requirements: 1.2, 3.2, 3.4, 3.5_
    - _Documentation: See `./documentation/langchain/INDEX.md` → `oss/python/langgraph/overview.md` for StateGraph construction and `oss/python/langgraph/graph-api.md` for graph API reference_
  - [ ] 6.2 Add helper functions for state initialization
    - Implement convert_openai_messages() to convert OpenAI format to LangChain messages
    - Implement build_initial_state() to create ChainState from ChatCompletionRequest
    - _Requirements: 1.3, 3.4_
    - _Documentation: See `./documentation/langchain/INDEX.md` → `oss/python/langchain/messages.md` for message types and conversion patterns_

- [ ] 7. Update configuration for chain settings
  - [ ] 7.1 Add chain configuration to `src/orchestrator_worker/config.py`
    - Add chain_analyze_model, chain_process_model, chain_synthesize_model settings
    - Add chain step max_tokens and temperature settings for each step
    - Add chain_analyze_timeout, chain_process_timeout, chain_synthesize_timeout settings
    - Add chain_enable_validation and chain_strict_validation boolean settings
    - _Requirements: 4.3, 5.2, 5.4_
    - _Documentation: See `./documentation/pydantic/LLM_INDEX.md` → ADVANCED section → `pydantic_settings/index.md` for BaseSettings and environment variable configuration_
  - [ ] 7.2 Add chain_config property to Settings class
    - Implement property that builds ChainConfig from individual settings
    - Return ChainConfig with all step configurations and timeout settings
    - _Requirements: 5.2, 5.4_
    - _Documentation: See `./documentation/pydantic/LLM_INDEX.md` → CORE section → `models/index.md` for computed properties using @property decorator_
  - [ ] 7.3 Update `.env.example` with chain configuration variables
    - Add all chain-specific environment variables with default values
    - Add comments explaining each setting
    - _Requirements: 5.2_

- [ ] 8. Integrate chain into FastAPI application
  - [ ] 8.1 Update `src/orchestrator_worker/main.py` startup event
    - Remove orchestrator agent initialization
    - Add chain graph initialization using build_chain_graph()
    - Store compiled graph in application state
    - Log successful chain initialization
    - _Requirements: 1.1, 4.1_
    - _Documentation: See `./documentation/fastapi/INDEX_AGENT.md` → `advanced/events.md` for startup/shutdown event patterns_
  - [ ] 8.2 Update `src/orchestrator_worker/main.py` shutdown event
    - Remove orchestrator agent shutdown
    - Add any necessary chain cleanup (if needed)
    - _Requirements: 1.1, 4.1_
    - _Documentation: See `./documentation/fastapi/INDEX_AGENT.md` → `advanced/events.md` for shutdown event patterns_
  - [ ] 8.3 Refactor `src/orchestrator_worker/api/v1/chat.py` endpoint
    - Remove orchestrator dependency injection
    - Add chain graph dependency from application state
    - Build initial ChainState from request using build_initial_state()
    - Replace orchestrator.process() with chain_graph.astream()
    - Use stream_mode="messages" for token-by-token streaming
    - Convert LangChain message chunks to OpenAI ChatCompletionChunk format
    - Yield SSE formatted chunks with "data: " prefix
    - Send "data: [DONE]" marker at end
    - Preserve error handling and timeout enforcement
    - _Requirements: 1.2, 1.3, 1.5, 4.3_
    - _Documentation: See `./documentation/fastapi/INDEX_AGENT.md` → `advanced/custom-response.md` for StreamingResponse and `./documentation/langchain/INDEX.md` → `oss/python/langchain/streaming.md` for LangChain streaming patterns_
  - [ ] 8.4 Add streaming response conversion utilities
    - Create convert_to_openai_chunk() function to transform LangChain messages to OpenAI format
    - Create create_error_chunk() function for error responses
    - Ensure proper handling of usage metadata in final chunk
    - _Requirements: 1.3, 1.5_
    - _Documentation: See existing `src/orchestrator_worker/models/openai.py` for OpenAI format reference_

- [ ] 9. Update logging and observability
  - [ ] 9.1 Create chain-specific logging utilities in `src/orchestrator_worker/utils/chain_logging.py`
    - Implement log_step_metrics() function for logging step execution details
    - Include step name, duration, tokens, cost, validation status
    - Maintain request ID propagation through chain
    - _Requirements: 4.2, 4.5_
  - [ ] 9.2 Update token tracking for chain steps
    - Modify `src/orchestrator_worker/utils/token_tracking.py` to support chain step tracking
    - Add aggregate_chain_metrics() function to sum tokens and costs across all steps
    - _Requirements: 4.5_
  - [ ] 9.3 Add chain execution logging to chat endpoint
    - Log chain start with request details
    - Log chain completion with total tokens, cost, and duration
    - Log validation failures with step and reason
    - _Requirements: 4.2_

- [ ] 10. Update error handling for chain execution
  - [ ] 10.1 Create chain-specific exceptions in `src/orchestrator_worker/utils/errors.py`
    - Add ChainExecutionError base exception
    - Add ValidationGateError with step and message fields
    - Add ChainTimeoutError with step and timeout fields
    - _Requirements: 2.5, 4.3_
  - [ ] 10.2 Update chat endpoint error handling
    - Catch ChainExecutionError and convert to appropriate HTTP response
    - Catch ValidationGateError and return 422 with validation details
    - Catch ChainTimeoutError and return 408 with timeout details
    - Preserve existing error handling for authentication, rate limiting, etc.
    - _Requirements: 1.4, 4.3_

- [ ] 11. Preserve existing middleware and security features
  - [ ] 11.1 Verify JWT authentication middleware still works
    - Test protected endpoints require valid JWT token
    - Test public endpoints (health checks) remain accessible
    - _Requirements: 1.4, 4.1_
  - [ ] 11.2 Verify security headers middleware still works
    - Test all responses include security headers
    - Test HSTS header only on HTTPS requests
    - _Requirements: 1.4, 4.1_
  - [ ] 11.3 Verify request size validation middleware still works
    - Test requests exceeding size limit return 413
    - Test health endpoints exempt from size validation
    - _Requirements: 1.4, 4.1_
  - [ ] 11.4 Verify rate limiting still works
    - Test rate limits enforced per user (JWT sub claim)
    - Test rate limit headers present in responses
    - Test 429 response when limit exceeded
    - _Requirements: 1.4, 4.1_
  - [ ] 11.5 Verify circuit breaker still works with LangChain
    - Test retry logic for transient Anthropic API errors
    - Test circuit opens after threshold failures
    - Test circuit closes after recovery period
    - _Requirements: 1.4, 4.4_

- [ ] 12. Update documentation
  - [ ] 12.1 Update `ARCHITECTURE.md` with prompt-chaining pattern
    - Replace orchestrator-worker pattern description with prompt-chaining
    - Document chain steps, validation gates, and state flow
    - Update architecture diagrams
    - Document LangChain and LangGraph usage
    - _Requirements: 6.1_
  - [ ] 12.2 Update `README.md` with prompt-chaining examples
    - Update overview and features sections
    - Replace orchestrator-worker examples with chain examples
    - Update use cases for prompt-chaining pattern
    - Update quick start guide
    - _Requirements: 6.2_
  - [ ] 12.3 Create migration guide document
    - Create `MIGRATION_GUIDE.md` documenting changes from orchestrator-worker
    - Explain conceptual differences between patterns
    - Document configuration changes
    - Provide code examples of before/after
    - _Requirements: 6.5_
  - [ ] 12.4 Create chain customization guide
    - Create `CHAIN_CUSTOMIZATION.md` with examples
    - Document how to add new chain steps
    - Document how to create custom validation gates
    - Document how to modify system prompts
    - Provide example chain configurations for common patterns
    - _Requirements: 6.3, 6.4_

- [ ] 13. Create tests for chain implementation
  - [ ] 13.1 Create unit tests for chain steps
    - Create `tests/unit/test_chain_steps.py`
    - Test analyze_step with mocked LLM responses
    - Test process_step with mocked LLM responses
    - Test synthesize_step with mocked streaming responses
    - Test error_step with various error scenarios
    - _Requirements: 7.1, 8.1, 8.2_
  - [ ] 13.2 Create unit tests for validation gates
    - Create `tests/unit/test_validation_gates.py`
    - Test AnalysisValidationGate with valid and invalid inputs
    - Test ProcessValidationGate with valid and invalid inputs
    - Test conditional edge functions return correct next step
    - _Requirements: 7.1, 8.5_
  - [ ] 13.3 Create unit tests for state transitions
    - Create `tests/unit/test_chain_state.py`
    - Test state updates between steps
    - Test message accumulation in state
    - Test metadata tracking through chain
    - _Requirements: 7.1, 8.3_
  - [ ] 13.4 Create integration tests for end-to-end chain execution
    - Create `tests/integration/test_chain_execution.py`
    - Test complete chain execution with real LLM calls (or mocked)
    - Test streaming response format matches OpenAI spec
    - Test validation failures trigger error step
    - Test timeout enforcement at each step
    - _Requirements: 7.1, 8.4_
  - [ ] 13.5 Create integration tests for FastAPI endpoint
    - Create `tests/integration/test_chain_api.py`
    - Test /v1/chat/completions endpoint with chain execution
    - Test authentication still required
    - Test streaming response format
    - Test error responses for validation failures
    - _Requirements: 7.1, 8.4_
  - [ ] 13.6 Create test fixtures for chain testing
    - Create fixtures in `tests/conftest.py`
    - Add mock_llm_response fixture
    - Add sample_chain_state fixture
    - Add chain_graph fixture
    - Add mock_chain_config fixture
    - _Requirements: 7.1, 8.3_

- [ ] 14. Remove orchestrator-worker code
  - [ ] 14.1 Remove orchestrator agent implementation
    - Delete or archive `src/orchestrator_worker/agents/orchestrator.py`
    - Remove orchestrator-specific tests
    - _Requirements: 1.1, 7.1_
  - [ ] 14.2 Remove worker agent implementation
    - Delete or archive `src/orchestrator_worker/agents/worker.py`
    - Remove worker-specific tests
    - _Requirements: 1.1, 7.1_
  - [ ] 14.3 Remove synthesizer agent implementation
    - Delete or archive `src/orchestrator_worker/agents/synthesizer.py`
    - Remove synthesizer-specific tests
    - _Requirements: 1.1, 7.1_
  - [ ] 14.4 Remove orchestrator-worker prompts
    - Delete or archive `src/orchestrator_worker/prompts/orchestrator_system.md`
    - Delete or archive `src/orchestrator_worker/prompts/worker_system.md`
    - Delete or archive `src/orchestrator_worker/prompts/synthesizer_system.md`
    - _Requirements: 1.1, 7.1_
  - [ ] 14.5 Remove orchestrator-worker models
    - Delete or archive `src/orchestrator_worker/models/internal.py` (TaskRequest, TaskResult)
    - Keep only models used by chain implementation
    - _Requirements: 1.1, 7.1_
  - [ ] 14.6 Update configuration to remove orchestrator-worker settings
    - Remove orchestrator_model, worker_model, synthesizer_model from config
    - Remove orchestrator/worker/synthesizer max_tokens and temperature settings
    - Remove worker_coordination_timeout and synthesis_timeout (replaced by chain timeouts)
    - Update `.env.example` to remove old settings
    - _Requirements: 1.1, 7.1_

- [ ] 15. Final validation and cleanup
  - [ ] 15.1 Run full test suite
    - Execute `./scripts/test.sh` and verify all tests pass
    - Check test coverage meets requirements
    - _Requirements: 7.1, 8.4_
  - [ ] 15.2 Test with Docker deployment
    - Build Docker image with `docker-compose build`
    - Start service with `docker-compose up`
    - Test health endpoints
    - Test chat completions endpoint with authentication
    - Verify streaming works correctly
    - _Requirements: 1.1, 1.3, 1.5_
  - [ ] 15.3 Verify all documentation is updated
    - Review ARCHITECTURE.md for accuracy
    - Review README.md for accuracy
    - Review MIGRATION_GUIDE.md for completeness
    - Review CHAIN_CUSTOMIZATION.md for clarity
    - _Requirements: 6.1, 6.2, 6.3, 6.4, 6.5_
  - [ ] 15.4 Code formatting and linting
    - Run `./scripts/format.sh` to format code
    - Fix any linting errors
    - _Requirements: 7.1_
